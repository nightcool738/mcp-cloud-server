#!/usr/bin/env node
// ======================
// GerÃ§ek MCP Protocol Server
// Model Context Protocol standardÄ±na uygun
// ======================

import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from "@modelcontextprotocol/sdk/types.js";
import fs from "fs/promises";
import os from "os";
import { exec } from "child_process";
import { promisify } from "util";
import OpenAI from "openai";

const execAsync = promisify(exec);

// OpenAI istemcisi
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ======================
// MCP Server Kurulumu
// ======================
const server = new Server(
  {
    name: "mcp-cloud-server",
    version: "1.1.0",
  },
  {
    capabilities: {
      tools: {},
    },
  }
);

// ======================
// Tool ImplementasyonlarÄ±
// ======================

const tools = {
  listFiles: async (params) => {
    try {
      const files = await fs.readdir(params.path || ".");
      return {
        content: [
          {
            type: "text",
            text: JSON.stringify({ files, path: params.path || "." }, null, 2),
          },
        ],
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `Hata: ${error.message}` }],
        isError: true,
      };
    }
  },

  readFile: async (params) => {
    try {
      const content = await fs.readFile(params.path, "utf8");
      return {
        content: [
          {
            type: "text",
            text: content,
          },
        ],
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `Hata: ${error.message}` }],
        isError: true,
      };
    }
  },

  writeFile: async (params) => {
    try {
      await fs.writeFile(params.path, params.content || "", "utf8");
      return {
        content: [
          {
            type: "text",
            text: `âœ… Dosya yazÄ±ldÄ±: ${params.path}`,
          },
        ],
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `Hata: ${error.message}` }],
        isError: true,
      };
    }
  },

  runScript: async (params) => {
    try {
      const { stdout, stderr } = await execAsync(params.path);
      return {
        content: [
          {
            type: "text",
            text: stdout || stderr || "Script Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±",
          },
        ],
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `Hata: ${error.message}` }],
        isError: true,
      };
    }
  },

  getSystemInfo: async () => {
    const info = {
      platform: os.platform(),
      arch: os.arch(),
      cpu: os.cpus()[0].model,
      totalMem: `${(os.totalmem() / 1024 / 1024 / 1024).toFixed(2)} GB`,
      freeMem: `${(os.freemem() / 1024 / 1024 / 1024).toFixed(2)} GB`,
      uptime: `${(os.uptime() / 3600).toFixed(2)} saat`,
      hostname: os.hostname(),
    };
    return {
      content: [
        {
          type: "text",
          text: JSON.stringify(info, null, 2),
        },
      ],
    };
  },

  chatGPT: async (params) => {
    try {
      const completion = await openai.chat.completions.create({
        model: params.model || "gpt-4",
        messages: [
          {
            role: "user",
            content: params.prompt,
          },
        ],
        temperature: params.temperature || 0.7,
        max_tokens: params.max_tokens || 1000,
      });

      return {
        content: [
          {
            type: "text",
            text: completion.choices[0].message.content,
          },
        ],
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `ChatGPT HatasÄ±: ${error.message}` }],
        isError: true,
      };
    }
  },
};

// ======================
// MCP Protocol Handlers
// ======================

// Tool listesi
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: "listFiles",
        description: "Belirtilen dizindeki dosyalarÄ± listeler",
        inputSchema: {
          type: "object",
          properties: {
            path: {
              type: "string",
              description: "Listelenecek klasÃ¶r yolu (varsayÄ±lan: mevcut dizin)",
            },
          },
        },
      },
      {
        name: "readFile",
        description: "Belirtilen dosyanÄ±n iÃ§eriÄŸini okur",
        inputSchema: {
          type: "object",
          properties: {
            path: {
              type: "string",
              description: "Okunacak dosya yolu",
            },
          },
          required: ["path"],
        },
      },
      {
        name: "writeFile",
        description: "Yeni bir dosya oluÅŸturur veya var olanÄ± yazar",
        inputSchema: {
          type: "object",
          properties: {
            path: {
              type: "string",
              description: "Dosya yolu",
            },
            content: {
              type: "string",
              description: "YazÄ±lacak iÃ§erik",
            },
          },
          required: ["path", "content"],
        },
      },
      {
        name: "runScript",
        description: "Yerel script veya komut Ã§alÄ±ÅŸtÄ±rÄ±r",
        inputSchema: {
          type: "object",
          properties: {
            path: {
              type: "string",
              description: "Ã‡alÄ±ÅŸtÄ±rÄ±lacak script yolu veya komut",
            },
          },
          required: ["path"],
        },
      },
      {
        name: "getSystemInfo",
        description: "Sistem bilgilerini dÃ¶ndÃ¼rÃ¼r (CPU, RAM, uptime vb.)",
        inputSchema: {
          type: "object",
          properties: {},
        },
      },
      {
        name: "chatGPT",
        description: "OpenAI ChatGPT ile sohbet et veya soru sor",
        inputSchema: {
          type: "object",
          properties: {
            prompt: {
              type: "string",
              description: "ChatGPT'ye sorulacak soru veya prompt",
            },
            model: {
              type: "string",
              description: "Model adÄ± (varsayÄ±lan: gpt-4)",
              enum: ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
            },
            temperature: {
              type: "number",
              description: "YaratÄ±cÄ±lÄ±k seviyesi 0-1 arasÄ± (varsayÄ±lan: 0.7)",
            },
            max_tokens: {
              type: "number",
              description: "Maksimum cevap uzunluÄŸu (varsayÄ±lan: 1000)",
            },
          },
          required: ["prompt"],
        },
      },
    ],
  };
});

// Tool Ã§aÄŸrÄ±larÄ±
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;

  if (!tools[name]) {
    return {
      content: [{ type: "text", text: `âŒ Bilinmeyen araÃ§: ${name}` }],
      isError: true,
    };
  }

  try {
    return await tools[name](args || {});
  } catch (error) {
    return {
      content: [{ type: "text", text: `âŒ Hata: ${error.message}` }],
      isError: true,
    };
  }
});

// ======================
// Server BaÅŸlat
// ======================
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("ğŸ¯ MCP Server baÅŸlatÄ±ldÄ± (stdio mode)");
}

main().catch((error) => {
  console.error("âŒ Server hatasÄ±:", error);
  process.exit(1);
});
